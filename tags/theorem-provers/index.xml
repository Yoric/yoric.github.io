<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Theorem Provers on Il y a du thé renversé au bord de la table !</title>
    <link>https://yoric.github.io/tags/theorem-provers/</link>
    <description>Recent content in Theorem Provers on Il y a du thé renversé au bord de la table !</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 06 Jan 2025 23:06:19 +0100</lastBuildDate>
    <atom:link href="https://yoric.github.io/tags/theorem-provers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI code plus performance minus brittle = ?</title>
      <link>https://yoric.github.io/post/formal-ai/</link>
      <pubDate>Mon, 06 Jan 2025 23:06:19 +0100</pubDate>
      <guid>https://yoric.github.io/post/formal-ai/</guid>
      <description>&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; &lt;em&gt;There&amp;rsquo;s a path towards AI that actually produces high-reliability, high-performance code, and it goes through formal methods and compilers.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Generative AI has been something of a controversial topic among developers. Some claim that it&amp;rsquo;s making their life easier, or even that they don&amp;rsquo;t need to code anymore and can let some agent do the job. Others claim that it&amp;rsquo;s unreliable, that it&amp;rsquo;s operating at the wrong level, and that it will never successfully replace developers.&lt;/p&gt;&#xA;&lt;p&gt;A few point out (correctly) that Earth simply cannot sustain the exponential energy requirements of AI – or even the exponential money demands of some famous AI company.&lt;/p&gt;&#xA;&lt;p&gt;For this post, let&amp;rsquo;s assume that Generative AI is here to say, and that it will eventually write (almost) all the code. This is by no mean a certainty, but it&amp;rsquo;s a possible scenario, or even a self-fulfilling prophecy.&lt;/p&gt;&#xA;&lt;p&gt;If this happens, there are two directions in which code-written-by-AI goes. Either AI will get better at writing reliable code, or we&amp;rsquo;ll get used to rolling dice whenever we use an AI to write code, and more often than not, end up with bad, bug-riddled, unreliable and slow AI-generated code. But hey, we&amp;rsquo;ll have managed to layoff all the developers (and all the voice actors, all the paralegals, all the book illustrators, etc.) so the money will flow and everybody&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; will be happy. Let&amp;rsquo;s be frank: given how the industry has evolved during the last ~40 years, the second option is the most likely. But maybe, just maybe, there is a path towards good AI code&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
